
\subsection*{What is a Sample?}
A sample is a relatively small subset of people, objects, groups, or events, that is selected from the population. Instead of surveying every recent college graduate in the United States, which would cost a great deal of time and money, we could instead select a sample of recent graduates, which would then be used to generalize the findings to the larger population.

\subsubsection{Type of Samples}
There are a variety of different types of samples in statistics. Each of these samples is named based upon how its members are obtained from the population. Below is a list with brief description of some of the most common statistical samples.

List of Sample Types

\begin{itemize}
\item \textbf{Random sample} – Here every member of the population is equally likely to be a member of the sample.
\item \textbf{Simple random sample} – Not only is this a random sample, but every group of n is equally likely to be the sample.
\item \textbf{Voluntary response sample} – Here subjects from the population determine whether they will be members of the sample or not.
\item \textbf{Convenience sample} - This type of sample is characterized by the selection of easy to obtain members from the population.
\item \textbf{Systematic sample} - A systematic sample is chosen on the basis of an ordered system.
\item \textbf{Cluster sample} – A cluster sample involves using a simple random sample of evident groups that the population contains.
\item \textbf{Stratified sample} - A stratified sample results when a population is split into at least two non-overlapping subpopulations.
\end{itemize}
It is important to know the distinctions between the different types of samples. For example, a simple random sample and a systematic random sample can be quite different from one another. Some of these samples are more useful than others in statistics. A convenience sample and voluntary response sample can be easy to perform, but these types of samples are not randomized to reduce or eliminate bias.

It is also good to have a working knowledge of all of these kinds of samples. Some situations call for something other than a simple random sample. We must be prepared to recognize these situations.


\subsection*{What Is the Difference Between a Parameter and a Statistic?}

In several disciplines the goal is to study a large group of individuals. These groups could be as varied as a species of bird, college freshmen in the U.S. or cars driven around the world. Statistics is used in all of these studies when it is infeasible or even impossible to study each and every member of the group of interest. Rather than measuring the wingspan of every bird of a species, asking survey questions to every college freshman, or measuring the fuel economy of every car in the world, we instead study and measure a subset of the group.

\subsubsection*{Populations and Samples}

The collection of everyone or everything that is to be analyzed in a study is called a \textbf{population}. As we have seen in the examples above, the population could be enormous in size. There could be millions or even billions of individuals in the population. But we must not think that the population has to be large. If our group being studied is fourth graders in a particular school, then the population consists only of these students. Depending on the school size, this could be less than a hundred students in our population.

To make our study less expensive in terms of time and resources, we only study a subset of the population. This subset is called a \textbf{sample}. Samples can be quite large or quite small. In theory one individual from a population constitutes a sample. Many applications of statistics require that a sample have at least 30 individuals.

\subsubsection*{Parameters and Statistics}

The main objective of Statistics as a science is to estimate a population parameter by use of sample statistics.

What we are typically after in a study is the \textbf{parameter}. A parameter is a numerical value that states something about the entire population being studied. For example, we may want to know the mean wingspan of the American bald eagle. This is a parameter, because it is describing all of the population.

Parameters are difficult if not impossible to obtain exactly. On the other hand, each parameter has a corresponding \textbf{statistic} that can be measured exactly. A statistic is a numerical value that states something about a sample. To extend the example above, we could catch 100 bald eagles and then measure the wingspan of each of these. The mean wingspan of the 100 eagles that we caught is a statistic.

The value of a parameter is a fixed number. In contrast to this, since a statistic depends upon a sample, the value of a statistic can vary from sample to sample. Suppose our population parameter has a value, unknown to us, of 10. One sample of size 50 has corresponding statistic with value 9.5. Another sample of size 50 from the same population has corresponding statistic with value 11.1.

\subsubsection*{Examples of Parameters and Statistics}

Below are some more example of parameters and statistics:

Suppose we study the population of dogs in Kansas City. A parameter of this population would be the mean height of all dogs in the city. A statistic would be the mean height of 50 of these dogs.
We will consider a study of high school seniors in the United States. A parameter of this population is the standard deviation of grade point averages of all high school seniors. A statistic is the standard deviation of the grade point averages of a sample of 1000 high school seniors.

\subsubsection*{Mnemonic Device}

There is a simple and straightforward way to remember what a parameter and statistic are measuring. All that we must do is look at the first letter of each word. A parameter measures something in a population, and a statistic measures something in a sample.

%--------------------------------------------------------------------------------------%
\subsection{Descriptive Statistics and Inferential Statistics}


Statistical procedures can be divided into two major categories: descriptive statistics and inferential statistics.
%Before discussing the differences between descriptive and inferential statistics, we must first be familiar with two important concepts in social science statistics: population and sample. A population is the total set of individuals, groups, objects, or events that the researcher is studying. For example, if we were studying employment patterns of recent U.S. college graduates, our population would likely be defined as every college student who graduated within the past one year from any college across the United States.


\subsubsection*{Descriptive Statistics}

Descriptive statistics includes statistical procedures that we use to describe the population we are studying. The data could be collected from either a sample or a population, but the results help us organize and describe data. Descriptive statistics can only be used to describe the group that is being studying. That is, the results cannot be generalized to any larger group.

Descriptive statistics are useful and serviceable if you do not need to extend your results to any larger group. However, much of social sciences tend to include studies that give us “universal” truths about segments of the population, such as all parents, all women, all victims, etc.

Frequency distributions, measures of central tendency (mean, median, and mode), and graphs like pie charts and bar charts that describe the data are all examples of descriptive statistics.

\subsubsection*{Inferential Statistics}

Inferential statistics is concerned with making predictions or inferences about a population from observations and analyses of a sample. That is, we can take the results of an analysis using a sample and can generalize it to the larger population that the sample represents. In order to do this, however, it is imperative that the sample is representative of the group to which it is being generalized.

To address this issue of generalization, we have tests of significance. A Chi-square or T-test, for example, can tell us the probability that the results of our analysis on the sample are representative of the population that the sample represents. In other words, these tests of significance tell us the probability that the results of the analysis could have occurred by chance when there is no relationship at all between the variables we studied in the population we studied.

Examples of inferential statistics include linear regression analyses, logistic regression analyses, ANOVA, correlation analyses, structural equation modeling, and survival analysis, to name a few.

%-------------------------------------------------------%